{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UCF101_subset.tar.gz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "hf_dataset_identifier = \"sayakpaul/ucf101-subset\"\n",
    "filename = \"UCF101_subset.tar.gz\"\n",
    "file_path = hf_hub_download(repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\", local_dir=\".\")\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement accelerate==1.1.1\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for accelerate==1.1.1\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r vivit-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                          Version\n",
      "-------------------------------- -----------\n",
      "absl-py                          0.10.0\n",
      "aiohappyeyeballs                 2.4.3\n",
      "aiohttp                          3.10.11\n",
      "aiosignal                        1.3.1\n",
      "astunparse                       1.6.3\n",
      "async-generator                  1.10\n",
      "async-timeout                    5.0.1\n",
      "attrs                            20.3.0\n",
      "backcall                         0.2.0\n",
      "bleach                           3.2.2\n",
      "cachetools                       4.2.1\n",
      "certifi                          2020.12.5\n",
      "chardet                          4.0.0\n",
      "charset-normalizer               3.4.0\n",
      "click                            7.1.2\n",
      "cloudpickle                      1.6.0\n",
      "contourpy                        1.1.1\n",
      "cycler                           0.12.1\n",
      "datasets                         2.21.0\n",
      "decorator                        4.4.2\n",
      "defusedxml                       0.6.0\n",
      "dill                             0.3.8\n",
      "entrypoints                      0.3\n",
      "filelock                         3.16.1\n",
      "Flask                            1.1.2\n",
      "flatbuffers                      1.12\n",
      "fonttools                        4.54.1\n",
      "frozenlist                       1.5.0\n",
      "fsspec                           2024.6.1\n",
      "future                           0.18.2\n",
      "gast                             0.3.3\n",
      "google-auth                      1.25.0\n",
      "google-auth-oauthlib             0.4.2\n",
      "google-pasta                     0.2.0\n",
      "googleapis-common-protos         1.52.0\n",
      "graphsurgeon                     0.4.5\n",
      "grpcio                           1.32.0\n",
      "h5py                             3.11.0\n",
      "horovod                          0.21.0\n",
      "huggingface-hub                  0.26.2\n",
      "idna                             2.10\n",
      "imageio                          2.35.1\n",
      "imageio-ffmpeg                   0.5.1\n",
      "importlib-resources              6.4.5\n",
      "ipykernel                        5.4.3\n",
      "ipython                          7.19.0\n",
      "ipython-genutils                 0.2.0\n",
      "itsdangerous                     1.1.0\n",
      "jedi                             0.18.0\n",
      "Jinja2                           2.11.2\n",
      "json5                            0.9.5\n",
      "jsonschema                       3.2.0\n",
      "jupyter-client                   6.1.11\n",
      "jupyter-core                     4.7.0\n",
      "jupyter-tensorboard              0.2.0\n",
      "jupyterlab                       1.2.14\n",
      "jupyterlab-pygments              0.1.2\n",
      "jupyterlab-server                1.2.0\n",
      "jupytext                         1.10.0\n",
      "Keras-Applications               1.0.8\n",
      "Keras-Preprocessing              1.1.2\n",
      "kiwisolver                       1.4.7\n",
      "Markdown                         3.3.3\n",
      "markdown-it-py                   0.6.2\n",
      "MarkupSafe                       1.1.1\n",
      "matplotlib                       3.3.3\n",
      "mdit-py-plugins                  0.2.5\n",
      "mistune                          0.8.4\n",
      "mock                             3.0.5\n",
      "moviepy                          1.0.3\n",
      "multidict                        6.1.0\n",
      "multiprocess                     0.70.16\n",
      "nbclient                         0.5.1\n",
      "nbconvert                        6.0.7\n",
      "nbformat                         5.0.8\n",
      "nest-asyncio                     1.4.3\n",
      "nltk                             3.4.5\n",
      "notebook                         6.0.3\n",
      "numpy                            1.19.2\n",
      "nvidia-dali-cuda110              0.29.0\n",
      "nvidia-dali-tf-plugin-cuda110    0.29.0\n",
      "nvidia-tensorboard-plugin-dlprof 0.11\n",
      "nvtx-plugins                     0.1.8\n",
      "oauthlib                         3.1.0\n",
      "opt-einsum                       3.3.0\n",
      "packaging                        24.2\n",
      "pandas                           1.1.5\n",
      "pandocfilters                    1.4.3\n",
      "parso                            0.8.1\n",
      "pexpect                          4.7.0\n",
      "pickleshare                      0.7.5\n",
      "pillow                           10.4.0\n",
      "pip                              21.0\n",
      "polygraphy                       0.23.1\n",
      "portpicker                       1.3.1\n",
      "proglog                          0.1.10\n",
      "prometheus-client                0.9.0\n",
      "promise                          2.3\n",
      "prompt-toolkit                   3.0.14\n",
      "propcache                        0.2.0\n",
      "protobuf                         3.14.0\n",
      "psutil                           5.7.0\n",
      "ptyprocess                       0.7.0\n",
      "pyarrow                          17.0.0\n",
      "pyasn1                           0.4.8\n",
      "pyasn1-modules                   0.2.8\n",
      "Pygments                         2.7.4\n",
      "pyparsing                        2.4.7\n",
      "pyrsistent                       0.17.3\n",
      "python-dateutil                  2.9.0.post0\n",
      "pytz                             2024.1\n",
      "PyYAML                           5.4.1\n",
      "pyzmq                            21.0.1\n",
      "regex                            2024.11.6\n",
      "requests                         2.32.3\n",
      "requests-oauthlib                1.3.0\n",
      "rsa                              4.7\n",
      "safetensors                      0.4.5\n",
      "scipy                            1.4.1\n",
      "seaborn                          0.13.2\n",
      "Send2Trash                       1.5.0\n",
      "setuptools                       52.0.0\n",
      "six                              1.15.0\n",
      "tensorboard                      2.4.1\n",
      "tensorboard-plugin-wit           1.8.0\n",
      "tensorflow                       2.4.0+nv\n",
      "tensorflow-addons                0.11.2\n",
      "tensorflow-datasets              3.2.1\n",
      "tensorflow-estimator             2.4.0\n",
      "tensorflow-metadata              0.27.0\n",
      "tensorrt                         7.2.2.3\n",
      "termcolor                        1.1.0\n",
      "terminado                        0.9.2\n",
      "testpath                         0.4.4\n",
      "tokenizers                       0.20.3\n",
      "toml                             0.10.2\n",
      "tornado                          6.1\n",
      "tqdm                             4.67.0\n",
      "traitlets                        5.0.5\n",
      "transformers                     4.46.2\n",
      "typeguard                        2.10.0\n",
      "typing-extensions                4.12.2\n",
      "tzdata                           2024.1\n",
      "uff                              0.6.9\n",
      "urllib3                          1.26.2\n",
      "wcwidth                          0.2.5\n",
      "webencodings                     0.5.1\n",
      "Werkzeug                         1.0.1\n",
      "wheel                            0.36.2\n",
      "wrapt                            1.12.1\n",
      "xxhash                           3.5.0\n",
      "yarl                             1.15.2\n",
      "zipp                             3.20.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "with tarfile.open(\"UCF101_subset.tar.gz\") as t:\n",
    "     t.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-09 13:51:32--  https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/data_handling.py\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/data_handling.py [following]\n",
      "--2024-11-09 13:51:32--  https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/data_handling.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2915 (2.8K) [text/plain]\n",
      "Saving to: ‘data_handling.py.1’\n",
      "\n",
      "data_handling.py.1  100%[===================>]   2.85K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-09 13:51:33 (22.7 MB/s) - ‘data_handling.py.1’ saved [2915/2915]\n",
      "\n",
      "--2024-11-09 13:51:33--  https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/model_configuration.py\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/model_configuration.py [following]\n",
      "--2024-11-09 13:51:33--  https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/model_configuration.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1139 (1.1K) [text/plain]\n",
      "Saving to: ‘model_configuration.py.1’\n",
      "\n",
      "model_configuration 100%[===================>]   1.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-09 13:51:33 (38.7 MB/s) - ‘model_configuration.py.1’ saved [1139/1139]\n",
      "\n",
      "--2024-11-09 13:51:33--  https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/preprocessing.py\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/preprocessing.py [following]\n",
      "--2024-11-09 13:51:34--  https://raw.githubusercontent.com/olonok69/LLM_Notebooks/main/video/fine_tune_ViViT/preprocessing.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8000::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1018 [text/plain]\n",
      "Saving to: ‘preprocessing.py.1’\n",
      "\n",
      "preprocessing.py.1  100%[===================>]    1018  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-09 13:51:34 (18.8 MB/s) - ‘preprocessing.py.1’ saved [1018/1018]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/data_handling.py\n",
    "!wget https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/model_configuration.py\n",
    "!wget https://github.com/olonok69/LLM_Notebooks/raw/main/video/fine_tune_ViViT/preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "Collecting datasets==2.21.0\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.17-py38-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.66.3\n",
      "  Using cached tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets==2.21.0) (1.19.2)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.21.0) (0.3.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets==2.21.0) (1.1.5)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.0 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.21.0) (5.4.1)\n",
      "Collecting requests>=2.32.2\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.21.0) (20.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (3.7.4.3)\n",
      "Collecting packaging\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==2.21.0) (20.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting yarl<2.0,>=1.12.0\n",
      "  Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[K     |████████████████████████████████| 319 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets==2.21.0) (1.26.2)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "\u001b[K     |████████████████████████████████| 143 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2020.12.5)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[K     |████████████████████████████████| 436 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==2.21.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==2.21.0) (1.15.0)\n",
      "Installing collected packages: typing-extensions, propcache, multidict, frozenlist, charset-normalizer, yarl, tqdm, requests, packaging, fsspec, filelock, async-timeout, aiosignal, aiohappyeyeballs, huggingface-hub, dill, aiohttp, xxhash, tokenizers, safetensors, regex, pyarrow, multiprocess, transformers, datasets\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.56.2\n",
      "    Uninstalling tqdm-4.56.2:\n",
      "      Successfully uninstalled tqdm-4.56.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.8\n",
      "    Uninstalling packaging-20.8:\n",
      "      Successfully uninstalled packaging-20.8\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.0+nv requires h5py~=2.10.0, but you have h5py 3.11.0 which is incompatible.\n",
      "tensorflow 2.4.0+nv requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 charset-normalizer-3.4.0 datasets-2.21.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.6.1 huggingface-hub-0.26.2 multidict-6.1.0 multiprocess-0.70.16 packaging-24.2 propcache-0.2.0 pyarrow-17.0.0 regex-2024.11.6 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2 typing-extensions-4.12.2 xxhash-3.5.0 yarl-1.15.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets==2.21.0 huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 797.1 MB 19 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/lib/python3.8/site-packages (from torch) (2024.6.1)\n",
      "Collecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.4 MB 98 kB/s  eta 0:00:010 MB 4.2 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 13 kB/s  eta 0:00:01 | 342.5 MB 4.1 MB/s eta 0:00:17\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 176.2 MB 173 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 4.1 MB/s eta 0:00:01                   | 29.5 MB 4.1 MB/s eta 0:00:41�███████████                | 97.8 MB 3.1 MB/s eta 0:00:32��████████████████████   | 177.9 MB 3.5 MB/s eta 0:00:066 MB 4.1 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (2.11.2)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 291 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (1.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /usr/lib/python3.8/site-packages (0.4.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.1 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/lib/python3.8/site-packages (from evaluate) (0.26.2)\n",
      "Requirement already satisfied: dill in /usr/lib/python3.8/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/lib/python3.8/site-packages (from evaluate) (2.21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3.8/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/lib/python3.8/site-packages (from evaluate) (4.67.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.8/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: xxhash in /usr/lib/python3.8/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/lib/python3.8/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.1.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/lib/python3.8/site-packages (from evaluate) (2024.6.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.19.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.10.11)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.15.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting platformdirs\n",
      "  Using cached platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (52.0.0)\n",
      "Collecting sentry-sdk>=2.0.0\n",
      "  Using cached sentry_sdk-2.18.0-py2.py3-none-any.whl (317 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.7.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.14.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2024.1)\n",
      "Installing collected packages: urllib3, smmap, numpy, gitdb, threadpoolctl, setproctitle, sentry-sdk, scipy, platformdirs, joblib, gitpython, docker-pycreds, wandb, scikit-learn\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.2\n",
      "    Uninstalling urllib3-1.26.2:\n",
      "      Successfully uninstalled urllib3-1.26.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.0+nv requires h5py~=2.10.0, but you have h5py 3.11.0 which is incompatible.\n",
      "tensorflow 2.4.0+nv requires numpy~=1.19.2, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow 2.4.0+nv requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "seaborn 0.13.2 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.3.3 which is incompatible.\n",
      "seaborn 0.13.2 requires pandas>=1.2, but you have pandas 1.1.5 which is incompatible.\u001b[0m\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 joblib-1.4.2 numpy-1.24.4 platformdirs-4.3.6 scikit-learn-1.3.2 scipy-1.10.1 sentry-sdk-2.18.0 setproctitle-1.3.3 smmap-5.0.1 threadpoolctl-3.5.0 urllib3-2.2.3 wandb-0.18.7\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate scikit-learn wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Tue Nov 12 11:30:39 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-db236b4664b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_configuration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/ayush/Major01/model_configuration.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     )\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0mevaluation_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_main_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     evaluation_instance = evaluation_cls(\n\u001b[1;32m    753\u001b[0m         \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mimport_main_class\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimport_main_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvaluationModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m\"\"\"Import a module at module_path and return its main class, a Metric by default\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mmain_cls_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluationModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14/accuracy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer, TrainingArguments, AdamW\n",
    "from model_configuration import *\n",
    "from transformers import Trainer\n",
    "from preprocessing import create_dataset\n",
    "from data_handling import frames_convert_and_create_dataset_dictionary\n",
    "from model_configuration import initialise_model\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "env_path =  \".env\"\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_configuration\n",
    "from model_configuration import compute_metrics\n",
    "import cv2\n",
    "import av\n",
    "from data_handling import sample_frame_indices, read_video_pyav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = av.open(\"./data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi\")\n",
    "container.streams.video[0].frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install moviepy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor\n",
    "container = av.open(\"./data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi\")\n",
    "indices = sample_frame_indices(clip_len=50, frame_sample_rate=2,seg_len=container.streams.video[0].frames)\n",
    "video = read_video_pyav(container=container, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74,  76,  78,  80,  82,  84,  86,  88,  90,  92,  94,  96,  98,\n",
       "       100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 125,\n",
       "       127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151,\n",
       "       153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g08_c04.avi number of Frames: 95\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g20_c05.avi number of Frames: 178\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g23_c01.avi number of Frames: 116\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g20_c07.avi number of Frames: 250\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g17_c01.avi number of Frames: 141\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g06_c04.avi number of Frames: 113\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g02_c03.avi number of Frames: 117\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g25_c01.avi number of Frames: 293\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g20_c03.avi number of Frames: 263\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g15_c05.avi number of Frames: 217\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g12_c03.avi number of Frames: 96\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g05_c01.avi number of Frames: 221\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g11_c01.avi number of Frames: 106\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g14_c03.avi number of Frames: 176\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g07_c06.avi number of Frames: 210\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g24_c01.avi number of Frames: 194\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g15_c01.avi number of Frames: 198\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g24_c05.avi number of Frames: 112\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g07_c02.avi number of Frames: 145\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g16_c05.avi number of Frames: 223\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g11_c03.avi number of Frames: 99\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g02_c05.avi number of Frames: 84\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g18_c02.avi number of Frames: 227\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g01_c03.avi number of Frames: 156\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g10_c04.avi number of Frames: 184\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g14_c01.avi number of Frames: 122\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g02_c01.avi number of Frames: 109\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g08_c02.avi number of Frames: 111\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g17_c05.avi number of Frames: 109\n",
      "Processing file data/UCF101_subset/train/BabyCrawling/v_BabyCrawling_g15_c03.avi number of Frames: 101\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g09_c06.avi number of Frames: 188\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g19_c02.avi number of Frames: 243\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g15_c06.avi number of Frames: 197\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c07.avi number of Frames: 145\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g24_c02.avi number of Frames: 105\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g06_c03.avi number of Frames: 245\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c05.avi number of Frames: 243\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c05.avi number of Frames: 93\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g04_c07.avi number of Frames: 158\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g18_c03.avi number of Frames: 157\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g02_c03.avi number of Frames: 216\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g07_c06.avi number of Frames: 162\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g16_c03.avi number of Frames: 114\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g10_c01.avi number of Frames: 153\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c03.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g12_c05.avi number of Frames: 127\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g21_c04.avi number of Frames: 227\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g11_c04.avi number of Frames: 138\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g18_c01.avi number of Frames: 159\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g07_c04.avi number of Frames: 142\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g13_c05.avi number of Frames: 119\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g11_c02.avi number of Frames: 178\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g22_c01.avi number of Frames: 170\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c06.avi number of Frames: 115\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g09_c02.avi number of Frames: 258\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g17_c04.avi number of Frames: 105\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g10_c05.avi number of Frames: 120\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g05_c02.avi number of Frames: 264\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g25_c01.avi number of Frames: 241\n",
      "Processing file data/UCF101_subset/train/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi number of Frames: 120\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g23_c05.avi number of Frames: 91\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g06_c05.avi number of Frames: 130\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g15_c02.avi number of Frames: 184\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g25_c04.avi number of Frames: 259\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g07_c01.avi number of Frames: 91\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g14_c04.avi number of Frames: 244\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g02_c01.avi number of Frames: 158\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g13_c03.avi number of Frames: 160\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g07_c05.avi number of Frames: 64\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g02_c05.avi number of Frames: 127\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g20_c05.avi number of Frames: 120\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g06_c03.avi number of Frames: 87\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g05_c04.avi number of Frames: 51\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g24_c06.avi number of Frames: 122\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g04_c03.avi number of Frames: 140\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g11_c06.avi number of Frames: 243\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g19_c03.avi number of Frames: 159\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g11_c04.avi number of Frames: 258\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g13_c07.avi number of Frames: 190\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g10_c03.avi number of Frames: 203\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g06_c01.avi number of Frames: 81\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g03_c02.avi number of Frames: 176\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g08_c01.avi number of Frames: 363\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g09_c02.avi number of Frames: 83\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g04_c01.avi number of Frames: 165\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g01_c04.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g22_c04.avi number of Frames: 73\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g24_c04.avi number of Frames: 121\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g10_c05.avi number of Frames: 188\n",
      "Processing file data/UCF101_subset/train/Archery/v_Archery_g22_c02.avi number of Frames: 70\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g18_c04.avi number of Frames: 119\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g02_c03.avi number of Frames: 98\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g23_c03.avi number of Frames: 135\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g21_c03.avi number of Frames: 143\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g22_c06.avi number of Frames: 172\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g07_c02.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g15_c03.avi number of Frames: 133\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g21_c01.avi number of Frames: 85\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g04_c05.avi number of Frames: 169\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g05_c02.avi number of Frames: 154\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g22_c02.avi number of Frames: 176\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g02_c01.avi number of Frames: 127\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g09_c04.avi number of Frames: 210\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g22_c04.avi number of Frames: 177\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g12_c04.avi number of Frames: 277\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g17_c03.avi number of Frames: 142\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g19_c04.avi number of Frames: 155\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g01_c04.avi number of Frames: 369\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g11_c04.avi number of Frames: 157\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g04_c01.avi number of Frames: 98\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g03_c03.avi number of Frames: 154\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g01_c02.avi number of Frames: 160\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g03_c01.avi number of Frames: 180\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g18_c02.avi number of Frames: 139\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g24_c05.avi number of Frames: 288\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g13_c03.avi number of Frames: 164\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g19_c02.avi number of Frames: 111\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g06_c03.avi number of Frames: 153\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g08_c02.avi number of Frames: 219\n",
      "Processing file data/UCF101_subset/train/ApplyLipstick/v_ApplyLipstick_g17_c01.avi number of Frames: 161\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g03_c01.avi number of Frames: 197\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g18_c03.avi number of Frames: 181\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g01_c03.avi number of Frames: 112\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g21_c05.avi number of Frames: 115\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g10_c02.avi number of Frames: 69\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g15_c03.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g24_c03.avi number of Frames: 100\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g06_c05.avi number of Frames: 102\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g03_c03.avi number of Frames: 101\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g21_c03.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g19_c01.avi number of Frames: 153\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g05_c01.avi number of Frames: 95\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g17_c01.avi number of Frames: 191\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g23_c04.avi number of Frames: 107\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g06_c01.avi number of Frames: 106\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g25_c01.avi number of Frames: 80\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g08_c04.avi number of Frames: 116\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g06_c03.avi number of Frames: 105\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g09_c02.avi number of Frames: 79\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g07_c02.avi number of Frames: 110\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g05_c03.avi number of Frames: 111\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g02_c03.avi number of Frames: 60\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g04_c01.avi number of Frames: 120\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g12_c04.avi number of Frames: 96\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g04_c03.avi number of Frames: 160\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g14_c03.avi number of Frames: 201\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g14_c01.avi number of Frames: 145\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g08_c02.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g10_c04.avi number of Frames: 122\n",
      "Processing file data/UCF101_subset/train/BalanceBeam/v_BalanceBeam_g19_c03.avi number of Frames: 118\n",
      "Processing file data/UCF101_subset/val/BabyCrawling/v_BabyCrawling_g09_c06.avi number of Frames: 119\n",
      "Processing file data/UCF101_subset/val/BabyCrawling/v_BabyCrawling_g21_c04.avi number of Frames: 189\n",
      "Processing file data/UCF101_subset/val/BabyCrawling/v_BabyCrawling_g13_c05.avi number of Frames: 85\n",
      "Processing file data/UCF101_subset/val/ApplyEyeMakeup/v_ApplyEyeMakeup_g14_c05.avi number of Frames: 160\n",
      "Processing file data/UCF101_subset/val/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi number of Frames: 164\n",
      "Processing file data/UCF101_subset/val/ApplyEyeMakeup/v_ApplyEyeMakeup_g20_c04.avi number of Frames: 220\n",
      "Processing file data/UCF101_subset/val/Archery/v_Archery_g18_c02.avi number of Frames: 291\n",
      "Processing file data/UCF101_subset/val/Archery/v_Archery_g18_c06.avi number of Frames: 160\n",
      "Processing file data/UCF101_subset/val/Archery/v_Archery_g12_c03.avi number of Frames: 436\n",
      "Processing file data/UCF101_subset/val/ApplyLipstick/v_ApplyLipstick_g10_c04.avi number of Frames: 247\n",
      "Processing file data/UCF101_subset/val/ApplyLipstick/v_ApplyLipstick_g20_c04.avi number of Frames: 140\n",
      "Processing file data/UCF101_subset/val/ApplyLipstick/v_ApplyLipstick_g25_c02.avi number of Frames: 151\n",
      "Processing file data/UCF101_subset/val/BalanceBeam/v_BalanceBeam_g16_c01.avi number of Frames: 124\n",
      "Processing file data/UCF101_subset/val/BalanceBeam/v_BalanceBeam_g22_c02.avi number of Frames: 96\n",
      "Processing file data/UCF101_subset/val/BalanceBeam/v_BalanceBeam_g13_c02.avi number of Frames: 125\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g04_c01.avi number of Frames: 127\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g19_c02.avi number of Frames: 170\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g19_c04.avi number of Frames: 144\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g22_c04.avi number of Frames: 193\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g22_c02.avi number of Frames: 197\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g22_c06.avi number of Frames: 92\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g03_c01.avi number of Frames: 215\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g03_c03.avi number of Frames: 198\n",
      "Processing file data/UCF101_subset/test/BabyCrawling/v_BabyCrawling_g04_c03.avi number of Frames: 159\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c02.avi number of Frames: 131\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c03.avi number of Frames: 115\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c04.avi number of Frames: 200\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g23_c06.avi number of Frames: 140\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c01.avi number of Frames: 209\n",
      "Processing file data/UCF101_subset/test/ApplyEyeMakeup/v_ApplyEyeMakeup_g03_c05.avi number of Frames: 146\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g21_c04.avi number of Frames: 205\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g16_c01.avi number of Frames: 151\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g17_c02.avi number of Frames: 94\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g16_c03.avi number of Frames: 206\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g16_c05.avi number of Frames: 262\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g17_c04.avi number of Frames: 66\n",
      "Processing file data/UCF101_subset/test/Archery/v_Archery_g21_c02.avi number of Frames: 175\n",
      "Processing file data/UCF101_subset/test/ApplyLipstick/v_ApplyLipstick_g14_c01.avi number of Frames: 176\n",
      "Processing file data/UCF101_subset/test/ApplyLipstick/v_ApplyLipstick_g16_c04.avi number of Frames: 173\n",
      "Processing file data/UCF101_subset/test/ApplyLipstick/v_ApplyLipstick_g14_c03.avi number of Frames: 174\n",
      "Processing file data/UCF101_subset/test/ApplyLipstick/v_ApplyLipstick_g16_c02.avi number of Frames: 165\n",
      "Processing file data/UCF101_subset/test/BalanceBeam/v_BalanceBeam_g11_c04.avi number of Frames: 116\n",
      "Processing file data/UCF101_subset/test/BalanceBeam/v_BalanceBeam_g20_c01.avi number of Frames: 84\n",
      "Processing file data/UCF101_subset/test/BalanceBeam/v_BalanceBeam_g20_c03.avi number of Frames: 100\n",
      "Processing file data/UCF101_subset/test/BalanceBeam/v_BalanceBeam_g11_c02.avi number of Frames: 68\n",
      "Min number frames 51\n"
     ]
    }
   ],
   "source": [
    "path_files = \"data/UCF101_subset\"\n",
    "video_dict, class_labels = frames_convert_and_create_dataset_dictionary(path_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['video', 'labels'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dict[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dict[0]['video'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BabyCrawling'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dict[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames, height, width, channels =  video_dict[0]['video'].shape\n",
    "num_frames, height, width, channels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Video Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: ['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam'].\n"
     ]
    }
   ],
   "source": [
    "class_labels = sorted(class_labels)\n",
    "label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(f\"Unique classes: {list(label2id.keys())}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting to class labels: 100%|██████████| 195/195 [00:00<00:00, 613.94 examples/s]\n",
      "Map: 100%|██████████| 195/195 [03:27<00:00,  1.06s/ examples]\n",
      "Map: 100%|██████████| 195/195 [01:31<00:00,  2.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "shuffled_dataset = create_dataset(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ClassLabel(names=['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam'], id=None),\n",
       " 'pixel_values': Sequence(feature=Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_dataset['train'].features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VivitForVideoClassification were not initialized from the model checkpoint at google/vivit-b-16x2-kinetics400 and are newly initialized because the shapes did not match:\n",
      "- vivit.embeddings.position_embeddings: found shape torch.Size([1, 3137, 768]) in the checkpoint and torch.Size([1, 981, 768]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model_configuration.initialise_model(shuffled_dataset, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install accelerate==1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_dir = \"/tmp/results\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=training_output_dir,         \n",
    "    num_train_epochs=3,             \n",
    "    per_device_train_batch_size=2,   \n",
    "    per_device_eval_batch_size=2,    \n",
    "    learning_rate=5e-05,            \n",
    "    weight_decay=0.01,              \n",
    "    logging_dir=\"./logs\",           \n",
    "    logging_steps=10,                \n",
    "    seed=42,                       \n",
    "    eval_strategy=\"steps\",    \n",
    "    eval_steps=10,                   \n",
    "    warmup_steps=int(0.1 * 20),      \n",
    "    optim=\"adamw_torch\",          \n",
    "    lr_scheduler_type=\"linear\",      \n",
    "    fp16=True,  \n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-05, betas=(0.9, 0.999), eps=1e-08)\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,              \n",
    "    train_dataset=shuffled_dataset[\"train\"],      \n",
    "    eval_dataset=shuffled_dataset[\"test\"],       \n",
    "    optimizers=(optimizer, None),  \n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4v4hltmb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-cherry-1</strong> at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/4v4hltmb' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/4v4hltmb</a><br/> View project at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241109_144946-4v4hltmb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4v4hltmb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/darth/Major01/wandb/run-20241109_145040-pm22xv17</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17' target=\"_blank\">morning-valley-2</a></strong> to <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78746036bac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_key =  os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=wandb_key)\n",
    "\n",
    "PROJECT = \"ViViT\"\n",
    "MODEL_NAME = \"google/vivit-b-16x2-kinetics400\"\n",
    "DATASET = \"sayakpaul/ucf101-subset\"\n",
    "\n",
    "wandb.init(project=PROJECT, # the project I am working on\n",
    "           tags=[MODEL_NAME, DATASET],\n",
    "           notes =\"Fine tuning ViViT with ucf101-subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-05, betas=(0.9, 0.999), eps=1e-08)\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,              \n",
    "    train_dataset=shuffled_dataset[\"train\"],      \n",
    "    eval_dataset=shuffled_dataset[\"test\"],       \n",
    "    optimizers=(optimizer, None),  \n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pm22xv17) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-valley-2</strong> at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/pm22xv17</a><br/> View project at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241109_145040-pm22xv17/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pm22xv17). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/darth/Major01/wandb/run-20241109_145121-cvd53vf6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/cvd53vf6' target=\"_blank\">cerulean-spaceship-3</a></strong> to <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/cvd53vf6' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/cvd53vf6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "  4%|▍         | 10/264 [00:11<04:20,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.648, 'grad_norm': 33.411678314208984, 'learning_rate': 4.885496183206107e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      "  4%|▍         | 10/264 [00:20<04:20,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.286291480064392, 'eval_accuracy': 0.45, 'eval_runtime': 9.2477, 'eval_samples_per_second': 2.163, 'eval_steps_per_second': 1.081, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/264 [00:30<04:39,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1584, 'grad_norm': 44.176692962646484, 'learning_rate': 4.713740458015267e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      "  8%|▊         | 20/264 [00:39<04:39,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1101562976837158, 'eval_accuracy': 0.65, 'eval_runtime': 9.1036, 'eval_samples_per_second': 2.197, 'eval_steps_per_second': 1.098, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 30/264 [00:50<04:23,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0708, 'grad_norm': 17.005741119384766, 'learning_rate': 4.522900763358779e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 11%|█▏        | 30/264 [00:59<04:23,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.744799792766571, 'eval_accuracy': 0.8, 'eval_runtime': 9.2289, 'eval_samples_per_second': 2.167, 'eval_steps_per_second': 1.084, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 40/264 [01:09<04:21,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6432, 'grad_norm': 26.458826065063477, 'learning_rate': 4.332061068702291e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 15%|█▌        | 40/264 [01:18<04:21,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6257659792900085, 'eval_accuracy': 0.8, 'eval_runtime': 9.169, 'eval_samples_per_second': 2.181, 'eval_steps_per_second': 1.091, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 50/264 [01:29<04:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5213, 'grad_norm': 26.027969360351562, 'learning_rate': 4.1412213740458014e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 19%|█▉        | 50/264 [01:38<04:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.553997814655304, 'eval_accuracy': 0.75, 'eval_runtime': 9.3817, 'eval_samples_per_second': 2.132, 'eval_steps_per_second': 1.066, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 60/264 [01:48<03:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4425, 'grad_norm': 9.949991226196289, 'learning_rate': 3.950381679389313e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 23%|██▎       | 60/264 [01:58<03:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4210754334926605, 'eval_accuracy': 0.9, 'eval_runtime': 9.385, 'eval_samples_per_second': 2.131, 'eval_steps_per_second': 1.066, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 70/264 [02:08<03:46,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4241, 'grad_norm': 23.707199096679688, 'learning_rate': 3.7595419847328244e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 27%|██▋       | 70/264 [02:18<03:46,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41632309556007385, 'eval_accuracy': 0.85, 'eval_runtime': 9.2678, 'eval_samples_per_second': 2.158, 'eval_steps_per_second': 1.079, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 80/264 [02:28<03:30,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5195, 'grad_norm': 31.68621253967285, 'learning_rate': 3.568702290076336e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 30%|███       | 80/264 [02:37<03:30,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6138721704483032, 'eval_accuracy': 0.7, 'eval_runtime': 9.3564, 'eval_samples_per_second': 2.138, 'eval_steps_per_second': 1.069, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 90/264 [02:47<03:24,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5145, 'grad_norm': 0.7145484089851379, 'learning_rate': 3.3778625954198475e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 34%|███▍      | 90/264 [02:56<03:24,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26420384645462036, 'eval_accuracy': 0.95, 'eval_runtime': 9.1963, 'eval_samples_per_second': 2.175, 'eval_steps_per_second': 1.087, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 100/264 [03:07<03:06,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1985, 'grad_norm': 2.672175168991089, 'learning_rate': 3.187022900763359e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 38%|███▊      | 100/264 [03:16<03:06,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20445671677589417, 'eval_accuracy': 0.95, 'eval_runtime': 9.3228, 'eval_samples_per_second': 2.145, 'eval_steps_per_second': 1.073, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 110/264 [03:26<02:55,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0702, 'grad_norm': 13.60689926147461, 'learning_rate': 2.9961832061068706e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 42%|████▏     | 110/264 [03:36<02:55,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37611904740333557, 'eval_accuracy': 0.75, 'eval_runtime': 9.3211, 'eval_samples_per_second': 2.146, 'eval_steps_per_second': 1.073, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 120/264 [03:46<02:46,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.155, 'grad_norm': 0.09088923037052155, 'learning_rate': 2.805343511450382e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 45%|████▌     | 120/264 [03:55<02:46,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15165233612060547, 'eval_accuracy': 0.95, 'eval_runtime': 9.2015, 'eval_samples_per_second': 2.174, 'eval_steps_per_second': 1.087, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 130/264 [04:06<02:33,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.048, 'grad_norm': 0.4784669876098633, 'learning_rate': 2.6145038167938934e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 49%|████▉     | 130/264 [04:15<02:33,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21213588118553162, 'eval_accuracy': 0.9, 'eval_runtime': 9.3626, 'eval_samples_per_second': 2.136, 'eval_steps_per_second': 1.068, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 140/264 [04:25<02:24,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1789, 'grad_norm': 0.45993635058403015, 'learning_rate': 2.4236641221374046e-05, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 53%|█████▎    | 140/264 [04:34<02:24,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1006142646074295, 'eval_accuracy': 1.0, 'eval_runtime': 9.2133, 'eval_samples_per_second': 2.171, 'eval_steps_per_second': 1.085, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 150/264 [04:45<02:09,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0403, 'grad_norm': 0.5529696345329285, 'learning_rate': 2.232824427480916e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 57%|█████▋    | 150/264 [04:54<02:09,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05935673788189888, 'eval_accuracy': 1.0, 'eval_runtime': 9.2964, 'eval_samples_per_second': 2.151, 'eval_steps_per_second': 1.076, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 160/264 [05:04<01:58,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0154, 'grad_norm': 0.15790769457817078, 'learning_rate': 2.0419847328244277e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 61%|██████    | 160/264 [05:14<01:58,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.038683317601680756, 'eval_accuracy': 1.0, 'eval_runtime': 9.2913, 'eval_samples_per_second': 2.153, 'eval_steps_per_second': 1.076, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 170/264 [05:24<01:47,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0172, 'grad_norm': 1.2312973737716675, 'learning_rate': 1.851145038167939e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 64%|██████▍   | 170/264 [05:33<01:47,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.036098577082157135, 'eval_accuracy': 1.0, 'eval_runtime': 9.2028, 'eval_samples_per_second': 2.173, 'eval_steps_per_second': 1.087, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 180/264 [05:43<01:35,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0076, 'grad_norm': 0.11387345939874649, 'learning_rate': 1.6603053435114505e-05, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 68%|██████▊   | 180/264 [05:52<01:35,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06169138103723526, 'eval_accuracy': 1.0, 'eval_runtime': 9.2923, 'eval_samples_per_second': 2.152, 'eval_steps_per_second': 1.076, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 190/264 [06:03<01:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0061, 'grad_norm': 0.06312558799982071, 'learning_rate': 1.4694656488549618e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 72%|███████▏  | 190/264 [06:12<01:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.047100018709897995, 'eval_accuracy': 1.0, 'eval_runtime': 9.2475, 'eval_samples_per_second': 2.163, 'eval_steps_per_second': 1.081, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 200/264 [06:22<01:13,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0034, 'grad_norm': 0.23209892213344574, 'learning_rate': 1.2786259541984732e-05, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 76%|███████▌  | 200/264 [06:31<01:13,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05480971187353134, 'eval_accuracy': 0.95, 'eval_runtime': 9.2679, 'eval_samples_per_second': 2.158, 'eval_steps_per_second': 1.079, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 210/264 [06:42<01:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0048, 'grad_norm': 0.023650895804166794, 'learning_rate': 1.0877862595419848e-05, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|███████▉  | 210/264 [06:51<01:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06784896552562714, 'eval_accuracy': 1.0, 'eval_runtime': 9.2453, 'eval_samples_per_second': 2.163, 'eval_steps_per_second': 1.082, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 220/264 [07:01<00:50,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0054, 'grad_norm': 0.07987233251333237, 'learning_rate': 8.969465648854961e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 83%|████████▎ | 220/264 [07:10<00:50,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.047449398785829544, 'eval_accuracy': 1.0, 'eval_runtime': 9.2684, 'eval_samples_per_second': 2.158, 'eval_steps_per_second': 1.079, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 230/264 [07:21<00:38,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.002, 'grad_norm': 0.06713747978210449, 'learning_rate': 7.061068702290078e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 87%|████████▋ | 230/264 [07:30<00:38,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02948460541665554, 'eval_accuracy': 1.0, 'eval_runtime': 9.2905, 'eval_samples_per_second': 2.153, 'eval_steps_per_second': 1.076, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 240/264 [07:40<00:28,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0025, 'grad_norm': 0.05533894896507263, 'learning_rate': 5.1526717557251914e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 91%|█████████ | 240/264 [07:49<00:28,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023304175585508347, 'eval_accuracy': 1.0, 'eval_runtime': 9.1685, 'eval_samples_per_second': 2.181, 'eval_steps_per_second': 1.091, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 250/264 [08:00<00:15,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0024, 'grad_norm': 0.07648076117038727, 'learning_rate': 3.2442748091603052e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 95%|█████████▍| 250/264 [08:09<00:15,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.020380020141601562, 'eval_accuracy': 1.0, 'eval_runtime': 9.3042, 'eval_samples_per_second': 2.15, 'eval_steps_per_second': 1.075, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 260/264 [08:19<00:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'grad_norm': 0.13047854602336884, 'learning_rate': 1.3358778625954198e-06, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 98%|█████████▊| 260/264 [08:29<00:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018836164847016335, 'eval_accuracy': 1.0, 'eval_runtime': 9.2971, 'eval_samples_per_second': 2.151, 'eval_steps_per_second': 1.076, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [08:32<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 512.519, 'train_samples_per_second': 1.024, 'train_steps_per_second': 0.515, 'train_loss': 0.29176113641623297, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▅▅▅▇▆▄▇▇▅▇▇██████▇██████</td></tr><tr><td>eval/loss</td><td>█▇▅▄▄▃▃▄▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▁▄▃██▅▇▃▆▆▃▇▄▆▆▃▆▅▅▅▅▆▃▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▄█▅▆▁▁▄▂▆▂▃▆▂▅▃▃▅▃▄▄▄▄▃▆▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▄█▅▆▁▁▄▂▆▃▃▆▁▅▃▃▆▃▄▄▅▄▃▆▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆█▄▅▅▃▅▆▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▄▃▃▃▃▃▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>1</td></tr><tr><td>eval/loss</td><td>0.01884</td></tr><tr><td>eval/runtime</td><td>9.2971</td></tr><tr><td>eval/samples_per_second</td><td>2.151</td></tr><tr><td>eval/steps_per_second</td><td>1.076</td></tr><tr><td>total_flos</td><td>4.12495606301184e+17</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>264</td></tr><tr><td>train/grad_norm</td><td>0.13048</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0015</td></tr><tr><td>train_loss</td><td>0.29176</td></tr><tr><td>train_runtime</td><td>512.519</td></tr><tr><td>train_samples_per_second</td><td>1.024</td></tr><tr><td>train_steps_per_second</td><td>0.515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-spaceship-3</strong> at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/cvd53vf6' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/cvd53vf6</a><br/> View project at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241109_145121-cvd53vf6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=PROJECT, job_type=\"train\", # the project I am working on\n",
    "           tags=[MODEL_NAME, DATASET],\n",
    "           notes =f\"Fine tuning {MODEL_NAME} with {DATASET}.\"):\n",
    "           train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         3.0\n",
      "  total_flos               = 384166470GF\n",
      "  train_loss               =      0.2918\n",
      "  train_runtime            =  0:08:32.51\n",
      "  train_samples_per_second =       1.024\n",
      "  train_steps_per_second   =       0.515\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"model\")\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_path = \"./model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/darth/Major01/wandb/run-20241109_150119-zq3is4os</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/zq3is4os' target=\"_blank\">clear-energy-4</a></strong> to <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/zq3is4os' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/zq3is4os</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model)... Done. 0.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-energy-4</strong> at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/zq3is4os' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT/runs/zq3is4os</a><br/> View project at: <a href='https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT' target=\"_blank\">https://wandb.ai/anookinskywalker-jaypee-institute-of-information-technology/ViViT</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241109_150119-zq3is4os/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=PROJECT, job_type=\"models\"):\n",
    "  artifact = wandb.Artifact(\"ViViT-Fine-tuned\", type=\"model\")\n",
    "  artifact.add_dir(custom_path)\n",
    "  wandb.save(custom_path)\n",
    "  wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
