{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bffb6cd1-5861-4c54-9799-e1f8bd961061",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_d1 = [\"skywalker290/Timesformers-d1\",\"skywalker290/videomae-base-finetuned-ucf101-subset\",\"skywalker290/Timesformer-Timesformer-d1\",\"skywalker290/Timesformer-vivit-d1\"]\n",
    "models_d2 = [\"skywalker290/VIVIT-d2\",\"skywalker290/Timesformers-d2\",\"skywalker290/Videomae-d2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40e70278-5575-4fbf-bc5f-a32690161eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoProcessor, VivitImageProcessor,VideoMAEImageProcessor\n",
    "image_processors = [\n",
    "                    [AutoProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\"),\"timesformer\"],\n",
    "                    [VivitImageProcessor.from_pretrained(\"google/vivit-b-16x2-kinetics400\"),\"vivit\"],\n",
    "                    [VideoMAEImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\"),\"videomae\"]\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0dbf1e9-8952-4164-af0d-69e8175c4a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7822444438934326, 'label': 'Abuse'}, {'score': 0.04848545789718628, 'label': 'Arson'}, {'score': 0.029100557789206505, 'label': 'Burglary'}, {'score': 0.028527015820145607, 'label': 'Shooting'}, {'score': 0.026359234005212784, 'label': 'Stealing'}, {'score': 0.016270173713564873, 'label': 'Vandalism'}, {'score': 0.015732167288661003, 'label': 'Assault'}, {'score': 0.01432537380605936, 'label': 'Explosion'}, {'score': 0.010794148780405521, 'label': 'Arrest'}, {'score': 0.008485277183353901, 'label': 'Fighting'}, {'score': 0.007636232767254114, 'label': 'Robbery'}, {'score': 0.007446467410773039, 'label': 'Shoplifting'}, {'score': 0.004593418911099434, 'label': 'RoadAccidents'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoProcessor, VivitImageProcessor,VideoMAEImageProcessor\n",
    "\n",
    "# Load the processor explicitly for ViViT\n",
    "image_processor = AutoProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "#image_processor = VivitImageProcessor.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
    "#image_processor = VideoMAEImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "\n",
    "# Load the pipeline with the processor\n",
    "for model in models_d2:\n",
    "    for image_processor in image_processors:\n",
    "        video_cls = pipeline(\n",
    "            task=\"video-classification\",\n",
    "            model=model,\n",
    "            device=0,\n",
    "            image_processor=image_processor[0]\n",
    "        )\n",
    "        result = video_cls(\"d1/Anomaly-detection-Dataset/test/Anomaly/Abuse008_x264.mp4\",top_k=13)\n",
    "        print(image_processor[1],model.split('/')[-1],result)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a36e84b6-a6e2-4f9a-b294-698cad23a8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c89fb9a006c4900b360893ec29ea4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/415 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained(\"skywalker290/Videomae-d2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5597d955-5c36-4229-a11a-31e9ec1fbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, video):\n",
    "    # (num_frames, num_channels, height, width)\n",
    "    perumuted_sample_test_video = video.permute(1, 0, 2, 3)\n",
    "    inputs = {\n",
    "        \"pixel_values\": perumuted_sample_test_video.unsqueeze(0),\n",
    "        \"labels\": torch.tensor(\n",
    "            [sample_test_video[\"label\"]]\n",
    "        ),  # this can be skipped if you don't have labels available.\n",
    "    }\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    model = model.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46cb8b7-01a0-4b38-ac24-e9ca8d8a8ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoImageProcessor, TimesformerForVideoClassification\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TimesformerForVideoClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/timesformer-base-finetuned-k400\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m rlogits \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md1/Anomaly-detection-Dataset/test/Anomaly/Abuse008_x264.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(model, video)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_inference\u001b[39m(model, video):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# (num_frames, num_channels, height, width)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     perumuted_sample_test_video \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: perumuted_sample_test_video\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m      7\u001b[0m             [sample_test_video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      8\u001b[0m         ),  \u001b[38;5;66;03m# this can be skipped if you don't have labels available.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     }\n\u001b[1;32m     11\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
    "\n",
    "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "rlogits = run_inference(model, \"d1/Anomaly-detection-Dataset/test/Anomaly/Abuse008_x264.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62299a97-a596-42b0-bfd6-803ae1b59c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3571890592.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    vivit videomae\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vivit-videomae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67a6687d-1333-4d08-bd66-731086a97b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorchvideo.data\n",
    "import torchvision\n",
    "\n",
    "dataset_root_path = 'd1/Anomaly-detection-Dataset'\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    Resize,\n",
    ")\n",
    "mean = image_processor.image_mean\n",
    "std = image_processor.image_std\n",
    "if \"shortest_edge\" in image_processor.size:\n",
    "    height = width = image_processor.size[\"shortest_edge\"]\n",
    "else:\n",
    "    height = image_processor.size[\"height\"]\n",
    "    width = image_processor.size[\"width\"]\n",
    "resize_to = (height, width)\n",
    "\n",
    "num_frames_to_sample = model.config.num_frames\n",
    "sample_rate = 4\n",
    "fps = 30\n",
    "clip_duration = num_frames_to_sample * sample_rate / fps\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        ApplyTransformToKey(\n",
    "            key=\"video\",\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(num_frames_to_sample),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize(mean, std),\n",
    "                    RandomShortSideScale(min_size=256, max_size=320),\n",
    "                    RandomCrop(resize_to),\n",
    "                    RandomHorizontalFlip(p=0.5),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(dataset_root_path, \"train\"),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\", clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        ApplyTransformToKey(\n",
    "            key=\"video\",\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    UniformTemporalSubsample(num_frames_to_sample),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize(mean, std),\n",
    "                    Resize(resize_to),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(dataset_root_path, \"val\"),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\", clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "test_dataset = pytorchvideo.data.Ucf101(\n",
    "    data_path=os.path.join(dataset_root_path, \"test\"),\n",
    "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\", clip_duration),\n",
    "    decode_audio=False,\n",
    "    transform=val_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3471200f-ef1f-43d0-813d-9b282bf56eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_MAX_CONSECUTIVE_FAILURES', '__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_clip_sampler', '_decode_audio', '_decoder', '_is_protocol', '_labeled_videos', '_loaded_clip', '_loaded_video_label', '_next_clip_start_time', '_transform', '_video_random_generator', '_video_sampler', '_video_sampler_iter', 'num_videos', 'video_path_handler', 'video_sampler']\n",
      "<pytorchvideo.data.video.VideoPathHandler object at 0x7ffd8e330be0>\n"
     ]
    }
   ],
   "source": [
    "print(dir(val_dataset))\n",
    "print(test_dataset.video_path_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f3ccaa3-b73a-4e93-ad9c-1228521f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, video):\n",
    "    # (num_frames, num_channels, height, width)\n",
    "    perumuted_sample_test_video = video.permute(1, 0, 2, 3)\n",
    "    inputs = {\n",
    "        \"pixel_values\": perumuted_sample_test_video.unsqueeze(0),\n",
    "        \"labels\": torch.tensor(\n",
    "            [sample_test_video[\"label\"]]\n",
    "        ),  # this can be skipped if you don't have labels available.\n",
    "    }\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    model = model.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "008b0483-3789-4bd7-b8e2-dda9a0c93f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorchvideo.data.labeled_video_dataset.LabeledVideoDataset at 0x7ffd8e333df0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28179eae-d929-4fc9-b748-8a6a56ae2f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb11dcac-09e5-40a0-8b3c-b99844d82785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5173, -3.8043]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f77ade1-9c1c-429f-8f3c-c13a4c60126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_sampler = pytorchvideo.data.make_clip_sampler(\"uniform\", clip_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0a49af8-f3eb-4358-ac94-d37b9aa893e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9934e-01, 6.6067e-04]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "logits = run_inference(model, sample_test_video[\"video\"])\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "# Your tensor\n",
    "logits = torch.tensor([[3.5173, -3.8043]], device='cuda:0')\n",
    "\n",
    "# Apply softmax\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3711c9ff-5e96-4926-8b8c-8bea4444c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Logistic Regression Accuracy: 0.5052631578947369\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Random Forest Accuracy: 0.5473684210526316\n",
      "Training SVM...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "SVM Accuracy: 0.5157894736842106\n",
      "Training KNN...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "KNN Accuracy: 0.47368421052631576\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   2.6s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   2.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   2.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   0.9s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   2.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END .......................................max_iter=200; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=500; total time=   2.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   1.3s\n",
      "[CV] END .......................................max_iter=500; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   4.4s\n",
      "[CV] END ......................................max_iter=1000; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   2.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   1.6s\n",
      "[CV] END .......................................max_iter=200; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=500; total time=   2.8s\n",
      "[CV] END .......................................max_iter=200; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=500; total time=   2.3s\n",
      "[CV] END .......................................max_iter=200; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   5.2s\n",
      "[CV] END .......................................max_iter=500; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.7s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   2.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=500; total time=   2.5s\n",
      "[CV] END ......................................max_iter=1000; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END ......................................n_neighbors=3; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   5.4s\n",
      "[CV] END .......................................max_iter=500; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   3.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END .......................................max_iter=500; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   5.9s\n",
      "[CV] END ......................................max_iter=1000; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   2.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   2.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   6.1s\n",
      "[CV] END .......................................max_iter=500; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   0.9s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   2.4s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   3.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=7, n_estimators=500; total time=   2.9s\n",
      "[CV] END ......................................max_iter=1000; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END ......................................n_neighbors=5; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END ......................................n_neighbors=7; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END .....................................n_neighbors=10; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   8.9s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   9.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   9.3s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   9.5s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=  11.3s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=  11.6s\n",
      "[CV] END ......................................max_iter=1000; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=  12.0s\n",
      "[CV] END .......................................max_iter=200; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   1.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=  12.5s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=  12.6s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=  15.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=  16.3s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=  16.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=  17.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=  17.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Take the CSV filename as input\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md2_model_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 85\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m     82\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features_scaled, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Train and evaluate all models\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[43mtrain_and_evaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 68\u001b[0m, in \u001b[0;36mtrain_and_evaluate_models\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Tune and train the model\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtune_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     71\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[81], line 50\u001b[0m, in \u001b[0;36mtune_and_train_model\u001b[0;34m(model, X_train, y_train)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Use GridSearchCV to tune hyperparameters\u001b[39;00m\n\u001b[1;32m     49\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Return the best model from the grid search\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1057\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1055\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_and_preprocess_data(csv_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.drop('path_to_video', axis=1)\n",
    "\n",
    "    # Check for missing values and handle them\n",
    "    df.fillna(0, inplace=True)  # Replace missing values with 0 (or another suitable method)\n",
    "\n",
    "    # Feature columns (all except 'label' column)\n",
    "    features = df.drop('label', axis=1)\n",
    "\n",
    "    # Target column\n",
    "    target = df['label']\n",
    "\n",
    "    # Encode labels (if 'label' is categorical)\n",
    "    label_encoder = LabelEncoder()\n",
    "    target = label_encoder.fit_transform(target)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return features_scaled, target\n",
    "\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'XGBoost': XGBClassifier()\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate and print accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "\n",
    "def main(csv_file):\n",
    "    # Load and preprocess the data\n",
    "    features_scaled, target = load_and_preprocess_data(csv_file)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train and evaluate all models\n",
    "    train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Take the CSV filename as input\n",
    "    csv_file = \"d2_model_dataset.csv\"\n",
    "    main(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d2a9cdb-5d34-4301-ab5d-783b877b7a27",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: named symbol not found\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Take the CSV filename as input\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md2_model_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change to your file path\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 117\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m    114\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(y_train))  \u001b[38;5;66;03m# Number of unique labels\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Train and evaluate the neural network\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mtrain_and_evaluate_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 82\u001b[0m, in \u001b[0;36mtrain_and_evaluate_neural_network\u001b[0;34m(X_train, X_test, y_train, y_test, input_size, output_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 82\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Print the training loss for every epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/torch/optim/adam.py:197\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/torch/optim/optimizer.py:430\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m is_compiling()\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built()\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[1;32m    429\u001b[0m     ):\n\u001b[0;32m--> 430\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    433\u001b[0m             group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[1;32m    434\u001b[0m         ):\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    438\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m             )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/timesformers/lib/python3.10/site-packages/torch/cuda/graphs.py:30\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: named symbol not found\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_and_preprocess_data(csv_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.drop('path_to_video', axis=1)\n",
    "\n",
    "    # Check for missing values and handle them\n",
    "    df.fillna(0, inplace=True)  # Replace missing values with 0 (or another suitable method)\n",
    "\n",
    "    # Feature columns (all except 'label' column)\n",
    "    features = df.drop('label', axis=1)\n",
    "\n",
    "    # Target column\n",
    "    target = df['label']\n",
    "\n",
    "    # Encode labels (if 'label' is categorical)\n",
    "    label_encoder = LabelEncoder()\n",
    "    target = label_encoder.fit_transform(target)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return features_scaled, target\n",
    "\n",
    "# Define a simple neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input to hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden to output layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax for multi-class classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Pass input through first layer\n",
    "        x = self.relu(x)  # Apply activation function\n",
    "        x = self.fc2(x)  # Pass through second layer\n",
    "        x = self.softmax(x)  # Apply softmax to get probabilities\n",
    "        return x\n",
    "\n",
    "# Train and evaluate the neural network\n",
    "def train_and_evaluate_neural_network(X_train, X_test, y_train, y_test, input_size, output_size):\n",
    "    # Convert to PyTorch tensors\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "    # DataLoader for batching\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Model initialization\n",
    "    model = NeuralNetwork(input_size=input_size, hidden_size=64, output_size=output_size)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(20):  # You can increase the number of epochs for better results\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the training loss for every epoch\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred.extend(predicted.numpy())\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Main function\n",
    "def main(csv_file):\n",
    "    # Load and preprocess the data\n",
    "    features_scaled, target = load_and_preprocess_data(csv_file)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define input and output sizes\n",
    "    input_size = X_train.shape[1]  # Number of features\n",
    "    output_size = len(set(y_train))  # Number of unique labels\n",
    "\n",
    "    # Train and evaluate the neural network\n",
    "    train_and_evaluate_neural_network(X_train, X_test, y_train, y_test, input_size, output_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Take the CSV filename as input\n",
    "    csv_file = \"d2_model_dataset.csv\"  # Change to your file path\n",
    "    main(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6118e8f5-3b5c-4bd6-9b9b-b8638485b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7733ac8-55f1-485b-9f43-6fdd39493f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
